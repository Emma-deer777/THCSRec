n_layers: 2
n_heads: 2
hidden_size: 64
inner_size: 256
hidden_dropout_prob: 0.5
attn_dropout_prob: 0.5
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.02
mask_ratio: 0.2
loss_type: 'CE'
customized_eval: 1
beta: 0.000005
enable_hg: 1
neg_sampling: null
topk: [5, 10, 101]
metrics: ['Recall', 'NDCG']
MAX_ITEM_LIST_LENGTH: 200
train_batch_size: 32
eval_batch_size: 32
hyper_len: 10
